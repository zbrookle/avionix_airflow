from typing import Dict, List, Optional

from avionix.kube.core import EnvVar
from cryptography.fernet import Fernet


def _create_fernet_key():
    return Fernet.generate_key().decode("utf-8")


class AirflowOptions:
    """
    Class for storing airflow options. Note that for storage specification the
    default unit is bytes, and you can use Mi or Gi to specify larger units.

    :param dag_sync_image: The image to use for syncing dags
    :param dag_sync_command: The commands to use for syncing dags
    :param dag_sync_schedule: Cron format schedule for how often to sync dags
    :param dag_storage: How much persistent storage to allocate for dags
    :param logs_storage: How much persistent storage to allocate for dags
    :param external_storage: How much external storage to allocate for dags
    :param default_executor_cpu: Default CPU to allocate to the executor \
        This is specified in number of vCPUs. You can fractions of CPUs as well or \
        milliCPUs (eg. "500m" for 500 milliCPUs)
    :param default_executor_memory: Default memory to allocate to the executor \
        This can be specified in bytes (default) or using standard prefix (eg. "20Mi")
    :param access_modes: Used to set access modes on the dag and logs volumes
    :param default_timezone: The default timezone
    :param core_executor: The core executor to use, supported executors are \
        "KubernetesExecutor" and "CeleryExecutor"
    :param namespace: The kubernetes namespace to use for the installation
    :param domain_name: The domain name to place on the ingress controller
    :param additional_vars: Any additional environment variables to place on the \
        airflow nodes. Note that you can add additional airflow configuration using \
        this setting. For more info on this see the \
        `airflow config documentation <https://airflow.apache.org/docs/stable/howto
        /set-config.html>`__
    :param fernet_key: The fernet key to use for airflow, this is autogenerated by \
        default, so unless you need to use an old fernet key, just leave this
    :param dags_paused_at_creation: Whether or not dags should be paused on creation
    :param worker_image: The docker image to use as the airflow worker
    :param worker_image_tag: The docker tag of the airflow worker image
    :param open_node_ports: Whether to expose the node ports
    :param local_mode: Whether or not to run in local mode
    """

    def __init__(
        self,
        dag_sync_image: str,
        dag_sync_command: List[str],
        dag_sync_schedule: str,
        dag_storage: str = "50Mi",
        logs_storage: str = "50Mi",
        external_storage: str = "50Mi",
        default_executor_cpu: int = 5,
        default_executor_memory: int = 2,
        access_modes: Optional[List[str]] = None,
        default_timezone: str = "utc",
        core_executor: str = "CeleryExecutor",
        namespace: str = "airflow",
        domain_name: Optional[str] = "www.avionix-airflow.com",
        additional_vars: Optional[Dict[str, str]] = None,
        fernet_key: str = "",
        dags_paused_at_creation: bool = True,
        worker_image: str = "airflow-image",
        worker_image_tag: str = "latest",
        open_node_ports: bool = False,
        local_mode: bool = False,
    ):
        self.dag_storage = dag_storage
        self.log_storage = logs_storage
        self.external_storage = external_storage
        self.default_executor_cpu = default_executor_cpu
        self.default_executor_memory = default_executor_memory
        self.access_modes = self.__get_access_modes(access_modes)
        self.dag_sync_image = dag_sync_image
        self.dag_sync_command = dag_sync_command
        self.dag_sync_schedule = dag_sync_schedule
        self.domain_name = domain_name
        self.default_time_zone = default_timezone
        self.core_executor = core_executor
        self.namespace = namespace
        self.__additional_vars = additional_vars if additional_vars is not None else {}
        self.fernet_key = fernet_key if fernet_key else _create_fernet_key()
        self.dags_paused_at_creation = dags_paused_at_creation
        self.worker_image = worker_image
        self.worker_image_tag = worker_image_tag
        self.open_node_ports = open_node_ports
        self.local_mode = local_mode
        if worker_image == "airflow-image" and not self.local_mode:
            self.worker_image = "zachb1996/avionix_airflow"

    @staticmethod
    def __get_access_modes(access_modes: Optional[List[str]]):
        if access_modes is None:
            return ["ReadWriteMany"]
        return access_modes

    @property
    def extra_env_vars(self):
        return [EnvVar(name, value) for name, value in self.__additional_vars.items()]

    @property
    def in_celery_mode(self):
        return self.core_executor == "CeleryExecutor"

    @property
    def in_kube_mode(self):
        return self.core_executor == "KubernetesExecutor"
